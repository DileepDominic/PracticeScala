{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9fb4551d"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DileepDominic/PracticeScala/blob/main/API_based_LLM_Access.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in Agentic and Generative AI\n",
        "## A programme by IISc and TalentSprint\n",
        "## Assignment-1: API-based LLM Access"
      ],
      "metadata": {
        "id": "oOivq-Ou2NVH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fb4551d"
      },
      "source": [
        "## Objective\n",
        "\n",
        "The objective of this assignment is to explore accessing Large Language Models (LLMs) via API, specifically using the OpenAI API. This involves setting up the environment, obtaining and securely storing an API key, creating an OpenAI client, and making API calls to generate text based on a given prompt. Additionally, the assignment includes a self-evaluation component to assess the performance of the API call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "562e47f5"
      },
      "source": [
        "## Information\n",
        "\n",
        "This notebook demonstrates how to interact with the OpenAI API using the Python client library. It covers the necessary steps from installing the required packages and setting up authentication to making a chat completion request and processing the response. The example prompt is designed to generate a detailed essay on a specific topic, including a self-evaluation in JSON format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKQ0Fvl_jNqU"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4UlAXa6hWqZ"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mAxYYRyhWq3"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P_-RHtFhWq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b9b1454-b004-4210-9e24-50a073e62afe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/submissions/record_ip.html?traineeId=2512300&recordId=159\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M1_AST_01_API_based_LLM_Access\" #name of the notebook\n",
        "\n",
        "batchId = \"IISC-AC-GENAI-02\"\n",
        "\n",
        "\n",
        "def print_message(message: str, color: str = \"red\"):\n",
        "    display(HTML(f\"<span style='color:{color};'>{message}</span>\"))\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword(), \"batch\" : batchId}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print_message(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print_message(\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support,\n",
        "              \"batch\" : batchId\n",
        "            }\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: \"\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read the OpenAI API Key**\n",
        "\n",
        "This cell retrieves the OpenAI API key securely stored in Google Colab's Secrets and sets it as an environment variable `OPENAI_API_KEY`. This is a recommended practice to avoid exposing your API key directly in the code.\n",
        "\n",
        "\n",
        "* Use an existing OpenAI API key, or Create a new one by visiting: https://platform.openai.com/api-keys\n",
        "\n",
        "* Save the key in Google Colab's Secrets\n",
        "\n",
        "* Read the key and save as an environment variable `OPENAI_API_KEY`"
      ],
      "metadata": {
        "id": "i7hsgudx3HnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the key in Colab's Secrets then load from there\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "57XOeLxJ3VFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create OpenAI client**\n",
        "\n",
        "This cell initializes the OpenAI client using the API key stored in the environment variable. This client object will be used to make API calls to OpenAI.\n"
      ],
      "metadata": {
        "id": "T6d8FRYLxtI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "wYx4MyKA4s12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Using API call**\n",
        "\n",
        "This cell demonstrates how to make a chat completion API call using the initialized OpenAI client.\n",
        "- A `prompt` variable is defined containing the instructions for the AI model to generate an essay and a self-evaluation report in JSON format.\n",
        "- `client.chat.completions.create()` is called with the following parameters:\n",
        "    - `model`: Specifies the OpenAI model to use (`gpt-4o` in this case).\n",
        "    - `messages`: A list of message objects representing the conversation history. In this case, it contains a single message with the role \"user\" and the content being the `prompt`.\n",
        "- The response from the API is stored in the `response` variable.\n",
        "- `print(response.choices[0].message.content)` extracts the generated text content from the response and prints it to the console."
      ],
      "metadata": {
        "id": "Pfs523nhjTeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write a detailed but concise essay (400–500 words) on the topic:\n",
        "“The role of artificial intelligence in addressing global climate change.”\n",
        "\n",
        "Your essay should include:\n",
        "\n",
        "1. A short introduction (2–3 sentences)\n",
        "2. 2–3 key arguments supported by real-world examples\n",
        "3. A brief conclusion summarizing your viewpoint\n",
        "\n",
        "Make sure the content is:\n",
        "Clear and logically structured\n",
        "Factually correct\n",
        "Engaging and easy to follow\n",
        "\n",
        "\n",
        "Self-Evaluation Section\n",
        "After completing your essay, provide a performance report in JSON format like this:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"response_length_tokens\": <approximate number of tokens in your response>,\n",
        "  \"time_taken_seconds\": <estimated total time to generate output>,\n",
        "  \"tokens_per_second\": <calculated or estimated speed>,\n",
        "  \"content_quality_score\": <1-10>,\n",
        "  \"factual_accuracy_score\": <1-10>,\n",
        "  \"relevance_score\": <1-10>,\n",
        "  \"coherence_score\": <1-10>,\n",
        "  \"creativity_score\": <1-10>,\n",
        "  \"overall_confidence_level\": \"<low|medium|high>\"\n",
        "}\n",
        "```\n",
        "If you cannot measure speed directly, estimate it based on your normal processing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "lZII9Hl0EhX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee71649-426e-456e-8720-e54bb35e06a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence (AI) is increasingly recognized as a critical tool in addressing the multifaceted challenge of global climate change. By leveraging vast amounts of data and complex algorithms, AI offers innovative solutions that enhance our ability to understand, mitigate, and adapt to climate impacts.\n",
            "\n",
            "One key role AI plays is in climate modeling and prediction. Traditional climate models require immense computational resources and can be limited by their complexity and the sheer volume of data. AI enhances these models by processing data more efficiently and accurately predicting climate patterns through machine learning techniques. For instance, Google's DeepMind has developed machine learning models that can more accurately forecast wind power output, improving the efficiency of wind farms by up to 20%. This advancement not only optimizes renewable energy use but also integrates it more reliably into power grids.\n",
            "\n",
            "Another significant contribution of AI is in optimizing energy consumption. AI-powered systems can manage energy use in buildings, transportation, and industry to reduce emissions. For example, IBM’s Green Horizon project employs AI to curtail energy consumption and enhance air quality in cities. By analyzing data from various sources, the system can predict pollution patterns and propose actionable insights to mitigate emissions. Such initiatives demonstrate AI's potential in systematically reducing the carbon footprint by promoting energy efficiency in urban environments.\n",
            "\n",
            "AI also plays a crucial role in monitoring deforestation and ecosystem health. Radar and satellite data, processed through AI algorithms, allow for real-time monitoring of deforestation and illegal logging activities, which are significant contributors to carbon emissions. The Global Forest Watch initiative utilizes AI to provide timely data on changes in forest cover, empowering governments and NGOs to take immediate action in environmental conservation.\n",
            "\n",
            "While AI presents these promising solutions, it is also important to recognize the ethical and operational challenges involved. The development and deployment of AI technologies demand significant resources and pose concerns about privacy and data security. Additionally, there is the challenge of ensuring equitable access to AI tools globally, as climate change is a universal problem requiring global cooperation and resource sharing.\n",
            "\n",
            "In conclusion, AI is poised to be a formidable ally in combating climate change by enhancing climate models, optimizing energy use, and maintaining ecosystem integrity. However, the pursuit of AI-based solutions must be balanced with ethical considerations and a commitment to global inclusivity. As we harness AI's potential, it is essential to focus on sustainable and equitable applications that align with the broader goal of creating a resilient future for our planet. \n",
            "\n",
            "```json\n",
            "{\n",
            "  \"response_length_tokens\": 442,\n",
            "  \"time_taken_seconds\": 60,\n",
            "  \"tokens_per_second\": 7.37,\n",
            "  \"content_quality_score\": 9,\n",
            "  \"factual_accuracy_score\": 9,\n",
            "  \"relevance_score\": 10,\n",
            "  \"coherence_score\": 9,\n",
            "  \"creativity_score\": 8,\n",
            "  \"overall_confidence_level\": \"high\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can access LLMs via API from other model providers as well such as Google Gemini API, Anthropic Claude API, etc."
      ],
      "metadata": {
        "id": "Sx7T9OAqRoSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Google Gemini API**"
      ],
      "metadata": {
        "id": "1H-Wvgrurrny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the key in Colab's Secrets then load from there\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "vWDluYRbqRHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Client\n",
        "from google import genai\n",
        "gemini_client = genai.Client()"
      ],
      "metadata": {
        "id": "bAYPDfz6qWcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide your prompt\n",
        "prompt = \"Which was built first - Taj Mahal, or Eiffel Tower\"\n",
        "\n",
        "# Make API call and get response\n",
        "gemini_response = gemini_client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt,\n",
        ")\n",
        "\n",
        "print(gemini_response.text)"
      ],
      "metadata": {
        "id": "pHRT6FOTpe8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c2490f-0e7c-427e-daa5-3903b28dc9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The **Taj Mahal** was built first.\n",
            "\n",
            "*   **Taj Mahal:** Construction began around **1631** and was completed around **1653**.\n",
            "*   **Eiffel Tower:** Construction began in **1887** and was completed in **1889**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Anthropic Claude API**"
      ],
      "metadata": {
        "id": "m3EhDTimuFIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the library\n",
        "!pip -q install anthropic"
      ],
      "metadata": {
        "id": "ozfOoz_EwGCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4235907-0dc6-492d-fc1e-cb6faa647444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/457.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m419.8/457.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the key in Colab's Secrets then load from there\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "oX3PNEivwEQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Client\n",
        "import anthropic\n",
        "anthropic_client = anthropic.Anthropic()"
      ],
      "metadata": {
        "id": "yN757qDvwq3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide your prompt\n",
        "prompt = \"Which was built first - Taj Mahal, or Eiffel Tower\"\n",
        "\n",
        "# Make API call and get response\n",
        "anthropic_response = anthropic_client.messages.create(\n",
        "    model=\"claude-sonnet-4-5\",\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(anthropic_response.content[0].text)"
      ],
      "metadata": {
        "id": "Kzq6DuhZuDgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1874d07-9977-47e5-bc26-4f1795a258bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Taj Mahal was built first. It was completed in **1653** in Agra, India, while the Eiffel Tower was completed in **1889** in Paris, France — more than 200 years later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErjQyyi4nR2n"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title Which LLM access method is most suitable when offline usage and data privacy are critical? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"Local tools such as Ollama or LM Studio\" #@param [\"\", \"Web-based LLM platforms\", \"API-based LLM services\", \"Local tools such as Ollama or LM Studio\", \"All of the above\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"As first lesson it is fine\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb47bb2b-fcc4-457b-fac0-7976decbed64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please complete the setup first.\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "$END$\n",
        "</center>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xJBPKsSoo1NQ"
      }
    }
  ]
}